---
UID: 20240903185606 
aliases: 
tags: 
source: 
cssclass: 
created: 2024-09-03
---

## LLM(大语言模型)：large language model

大语言模型一般指在大规模的文本语料上训练，包含百亿甚至更多参数的语言模型。大语言模型采用的架构目前基本是基于transformer的架构。那么LLM近期爆火，在之前却没有很好的表现的一个很重要原因是，只有语言模型的规模达到一定量级的时候，某些能力才会出现。（称之为**涌现能力**）。代表性的包括：上下文学习、指令遵循、逐步推理等等。

- 如Transformer架构的GPT-3、BERT、T5等模型。这些模型通过在海量数据上进行训练，能够学习到丰富的语言和知识表示，并展现出强大的自然语言处理能力。

